import pandas as pd
from Bio import SeqIO

# --- inputs (edit these) ---
TE_PATH = "TE Data - Li.csv"                 # columns: gene, TE  (or locus_tag, TE)
GB_PATH = "GCF_000005845.2_ASM584v2_genomic.gbff"  # E. coli K-12 MG1655 GenBank file
JOIN_KEY = "gene"                  # choose: "gene" or "locus_tag"
INCLUDE_STOP = False               # include stop codon in codon list?

# --- load TE table ---
te = pd.read_csv(TE_PATH)

# --- helper to split into codons ---
def to_codons(seq, include_stop=False):
    s = str(seq).upper()
    # optional: drop terminal stop if present
    if not include_stop and s.endswith(("TAA","TAG","TGA")) and len(s) % 3 == 0:
        s = s[:-3]
    # keep only complete triplets
    L = len(s) - (len(s) % 3)
    s = s[:L]
    return [s[i:i+3] for i in range(0, len(s), 3)]

records = SeqIO.parse(GB_PATH, "genbank")
rows = []

for rec in records:
    for f in rec.features:
        if f.type != "CDS":
            continue

        # Skip pseudogenes / partials if flagged
        quals = f.qualifiers
        if "pseudo" in quals:
            continue

        # Identify keys
        gene = quals.get("gene", [None])[0]
        locus_tag = quals.get("locus_tag", [None])[0]
        protein_id = quals.get("protein_id", [None])[0]

        # Extract CDS DNA
        try:
            cds_seq = f.extract(rec.seq)
        except Exception:
            continue

        if len(cds_seq) < 3 or len(cds_seq) % 3 != 0:
            # keep but flag; some entries may have exceptions
            pass

        codons = to_codons(cds_seq, include_stop=INCLUDE_STOP)

        rows.append({
            "gene": gene,
            "locus_tag": locus_tag,
            "protein_id": protein_id,
            "cds_len_nt": len(cds_seq),
            "n_codons": len(codons),
            "codon_seq": cds_seq,    
            "codons_list": codons              # raw list if you need it later
        })

cds_df = pd.DataFrame(rows)

import numpy as np

# Add ranking fields (if you didn't keep qualifiers, you can rebuild them; hereâ€™s a safe heuristic)
# If you still have qualifiers, replace these with the actual flags from qualifiers.
cds_df = cds_df.copy()

# If you captured these earlier, great; if not, default to False
for col in ["is_pseudo", "has_transl_except", "is_partial"]:
    if col not in cds_df.columns:
        cds_df[col] = False

# Rank: prefer (non-pseudo) > (no transl_except) > (not partial) > (longer CDS)
cds_df["_rank_tuple"] = list(zip(
    cds_df["is_pseudo"].astype(bool),          # False (0) beats True (1)
    cds_df["has_transl_except"].astype(bool),  # False beats True
    cds_df["is_partial"].astype(bool),         # False beats True
    -cds_df["cds_len_nt"].fillna(0).astype(int) # longer beats shorter
))

# Sort so best rows come first per key
cds_df_sorted = cds_df.sort_values(by=["_rank_tuple"])

# Collapse to one row per join key
cds_df_unique = cds_df_sorted.drop_duplicates(subset=[JOIN_KEY], keep="first").drop(columns="_rank_tuple")

# Sanity check
assert not cds_df_unique[JOIN_KEY].duplicated().any(), "Still have duplicated keys after collapse."
print(f"Collapsed from {len(cds_df)} to {len(cds_df_unique)} CDS rows on key={JOIN_KEY}")

# --- pick the join column that exists in your TE table ---
if JOIN_KEY not in te.columns:
    # fall back: if TE has 'gene' but not 'locus_tag', join on gene; else try locus_tag
    if "gene" in te.columns and "gene" in cds_df.columns:
        JOIN_KEY = "gene"
    elif "locus_tag" in te.columns and "locus_tag" in cds_df.columns:
        JOIN_KEY = "locus_tag"
    else:
        raise ValueError("Couldn't find a common join key between TE and CDS tables.")

# --- perform the join (left: keep all TE rows) ---
out = te.merge(cds_df_unique, on=JOIN_KEY, how="left", validate="m:1")
n_unmatched = out["codon_seq"].isna().sum()
print(f"Unmatched TE rows after join: {n_unmatched}")

# --- save ---
out.to_csv("te_with_codons.csv", index=False)
print("Wrote te_with_codons.csv")