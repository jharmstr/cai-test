[{"name": "app.py", "content": "from __future__ import annotations\n\nfrom shiny import App, Inputs, Outputs, Session, reactive, render, ui\nfrom shiny.types import FileInfo\nfrom Bio import SeqIO\nfrom collections import defaultdict, Counter\nimport math, pandas as pd, io, matplotlib.pyplot as plt, seaborn as sns, re\nfrom typing import Dict, List, Tuple, Optional, Callable\n\n# ---------------- Codon table / utilities ----------------\nCODON_TABLE: Dict[str, List[str]] = {\n    'F': ['TTT', 'TTC'], 'L': ['TTA', 'TTG', 'CTT', 'CTC', 'CTA', 'CTG'],\n    'I': ['ATT', 'ATC', 'ATA'], 'M': ['ATG'], 'V': ['GTT', 'GTC', 'GTA', 'GTG'],\n    'S': ['TCT', 'TCC', 'TCA', 'TCG', 'AGT', 'AGC'], 'P': ['CCT', 'CCC', 'CCA', 'CCG'],\n    'T': ['ACT', 'ACC', 'ACA', 'ACG'], 'A': ['GCT', 'GCC', 'GCA', 'GCG'],\n    'Y': ['TAT', 'TAC'], 'H': ['CAT', 'CAC'], 'Q': ['CAA', 'CAG'],\n    'N': ['AAT', 'AAC'], 'K': ['AAA', 'AAG'], 'D': ['GAT', 'GAC'],\n    'E': ['GAA', 'GAG'], 'C': ['TGT', 'TGC'], 'W': ['TGG'],\n    'R': ['CGT', 'CGC', 'CGA', 'CGG', 'AGA', 'AGG'], 'G': ['GGT', 'GGC', 'GGA', 'GGG']\n}\nSENSE_CODONS = sorted({c for v in CODON_TABLE.values() for c in v})\nAA_FOR = {c: aa for aa, codons in CODON_TABLE.items() for c in codons}\n\ndef normalize_seq(s: str) -> str:\n    s = (s or \"\").upper().replace(\" \", \"\").replace(\"\\n\", \"\").replace(\"U\", \"T\")\n    s = re.sub(r\"[^ACGT]\", \"\", s)\n    n = len(s) - (len(s) % 3)\n    return s[:n]\n\n# ---------------- Built-in CAI/tAI weights ----------------\nECOLI_CAI = {\n    'TTT': 0.58, 'TTC': 1.00, 'TTA': 0.02, 'TTG': 0.07, 'CTT': 0.13, 'CTC': 0.20,\n    'CTA': 0.02, 'CTG': 1.00, 'ATT': 0.49, 'ATC': 1.00, 'ATA': 0.03, 'ATG': 1.00,\n    'GTT': 0.35, 'GTC': 0.47, 'GTA': 0.07, 'GTG': 1.00, 'TCT': 0.22, 'TCC': 0.39,\n    'TCA': 0.15, 'TCG': 0.06, 'AGT': 0.15, 'AGC': 1.00, 'CCT': 0.42, 'CCC': 0.29,\n    'CCA': 0.28, 'CCG': 1.00, 'ACT': 0.23, 'ACC': 1.00, 'ACA': 0.36, 'ACG': 0.47,\n    'GCT': 0.37, 'GCC': 1.00, 'GCA': 0.28, 'GCG': 0.76, 'TAT': 0.43, 'TAC': 1.00,\n    'CAT': 0.43, 'CAC': 1.00, 'CAA': 0.27, 'CAG': 1.00, 'AAT': 0.47, 'AAC': 1.00,\n    'AAA': 0.44, 'AAG': 1.00, 'GAT': 0.63, 'GAC': 1.00, 'GAA': 0.68, 'GAG': 1.00,\n    'TGT': 0.44, 'TGC': 1.00, 'TGG': 1.00, 'CGT': 0.36, 'CGC': 1.00, 'CGA': 0.07,\n    'CGG': 0.11, 'AGA': 0.02, 'AGG': 0.02, 'GGT': 0.41, 'GGC': 1.00, 'GGA': 0.25,\n    'GGG': 0.50\n}\nECOLI_TAI = {\n    'TTT': 0.43, 'TTC': 1.00, 'TTA': 0.17, 'TTG': 0.32, 'CTT': 0.22, 'CTC': 0.38,\n    'CTA': 0.07, 'CTG': 1.00, 'ATT': 0.38, 'ATC': 0.69, 'ATA': 0.10, 'ATG': 1.00,\n    'GTT': 0.31, 'GTC': 0.44, 'GTA': 0.09, 'GTG': 1.00, 'TCT': 0.32, 'TCC': 0.51,\n    'TCA': 0.27, 'TCG': 0.23, 'AGT': 0.25, 'AGC': 0.55, 'CCT': 0.31, 'CCC': 0.29,\n    'CCA': 0.25, 'CCG': 1.00, 'ACT': 0.28, 'ACC': 1.00, 'ACA': 0.38, 'ACG': 0.47,\n    'GCT': 0.37, 'GCC': 1.00, 'GCA': 0.29, 'GCG': 0.69, 'TAT': 0.37, 'TAC': 1.00,\n    'CAT': 0.41, 'CAC': 1.00, 'CAA': 0.36, 'CAG': 1.00, 'AAT': 0.48, 'AAC': 1.00,\n    'AAA': 0.38, 'AAG': 1.00, 'GAT': 0.54, 'GAC': 1.00, 'GAA': 0.59, 'GAG': 1.00,\n    'TGT': 0.45, 'TGC': 1.00, 'TGG': 1.00, 'CGT': 0.27, 'CGC': 1.00, 'CGA': 0.09,\n    'CGG': 0.13, 'AGA': 0.05, 'AGG': 0.05, 'GGT': 0.39, 'GGC': 1.00, 'GGA': 0.21,\n    'GGG': 0.47\n}\n\n# S. cerevisiae (default weights)\nSCER_CAI = {\n    'TTT':0.31,'TTC':1.00,'TTA':0.06,'TTG':0.10,'CTT':0.18,'CTC':0.28,'CTA':0.05,'CTG':1.00,\n    'ATT':0.45,'ATC':1.00,'ATA':0.10,'ATG':1.00,'GTT':0.36,'GTC':0.63,'GTA':0.11,'GTG':1.00,\n    'TCT':0.35,'TCC':0.73,'TCA':0.28,'TCG':0.09,'AGT':0.22,'AGC':1.00,'CCT':0.36,'CCC':0.32,\n    'CCA':0.31,'CCG':1.00,'ACT':0.44,'ACC':1.00,'ACA':0.52,'ACG':0.22,'GCT':0.42,'GCC':1.00,\n    'GCA':0.51,'GCG':0.19,'TAT':0.42,'TAC':1.00,'CAT':0.46,'CAC':1.00,'CAA':0.24,'CAG':1.00,\n    'AAT':0.52,'AAC':1.00,'AAA':0.53,'AAG':1.00,'GAT':0.60,'GAC':1.00,'GAA':0.67,'GAG':1.00,\n    'TGT':0.59,'TGC':1.00,'TGG':1.00,'CGT':0.23,'CGC':1.00,'CGA':0.08,'CGG':0.14,'AGA':0.07,\n    'AGG':0.08,'GGT':0.53,'GGC':1.00,'GGA':0.34,'GGG':0.58\n}\nSCER_TAI = {\n    'TTT':0.36,'TTC':1.00,'TTA':0.12,'TTG':0.23,'CTT':0.24,'CTC':0.43,'CTA':0.10,'CTG':1.00,\n    'ATT':0.41,'ATC':0.78,'ATA':0.14,'ATG':1.00,'GTT':0.35,'GTC':0.58,'GTA':0.13,'GTG':1.00,\n    'TCT':0.40,'TCC':0.69,'TCA':0.30,'TCG':0.16,'AGT':0.27,'AGC':1.00,'CCT':0.35,'CCC':0.31,\n    'CCA':0.29,'CCG':1.00,'ACT':0.38,'ACC':1.00,'ACA':0.47,'ACG':0.22,'GCT':0.39,'GCC':1.00,\n    'GCA':0.46,'GCG':0.23,'TAT':0.41,'TAC':1.00,'CAT':0.46,'CAC':1.00,'CAA':0.30,'CAG':1.00,\n    'AAT':0.49,'AAC':1.00,'AAA':0.44,'AAG':1.00,'GAT':0.56,'GAC':1.00,'GAA':0.61,'GAG':1.00,\n    'TGT':0.51,'TGC':1.00,'TGG':1.00,'CGT':0.25,'CGC':1.00,'CGA':0.12,'CGG':0.17,'AGA':0.10,\n    'AGG':0.12,'GGT':0.49,'GGC':1.00,'GGA':0.32,'GGG':0.56\n}\n\n#COPT ratio values\n\nECO_COPT_RATIO = {\n    'GCT': 1.717, 'GCC': 0.639, 'GCA': 0.986, 'GCG': 0.900,\n    'CGT': 2.934, 'CGC': 1.189, 'CGA': 0.276, 'CGG': 0.210, 'AGA': 0.144, 'AGG': 0.153,\n    'AAT': 0.271, 'AAC': 3.693,\n    'GAT': 0.455, 'GAC': 2.198,\n    'TGT': 0.622, 'TGC': 1.608,\n    'CAA': 0.507, 'CAG': 1.972,\n    'GAA': 1.331, 'GAG': 0.751,\n    'GGT': 1.840, 'GGC': 1.474, 'GGA': 0.234, 'GGG': 0.327,\n    'CAT': 0.381, 'CAC': 2.622,\n    'ATT': 0.539, 'ATC': 3.406, 'ATA': 0.130,\n    'CTT': 0.542, 'CTC': 0.744, 'CTA': 0.285, 'CTG': 3.759, 'TTA': 0.301, 'TTG': 0.527,\n    'AAA': 1.136, 'AAG': 0.881,\n    'TTT': 0.285, 'TTC': 3.510,\n    'CCT': 0.526, 'CCC': 0.278, 'CCA': 0.737, 'CCG': 2.883,\n    'TCT': 2.360, 'TCC': 2.142, 'TCA': 0.418, 'TCG': 0.581, 'AGT': 0.343, 'AGC': 1.086,\n    'ACT': 1.963, 'ACC': 1.886, 'ACA': 0.293, 'ACG': 0.413,\n    'TAT': 0.348, 'TAC': 2.876,\n    'GTT': 1.668, 'GTC': 0.579, 'GTA': 1.221, 'GTG': 0.707,\n    'ATG': 1.000,  # Met\n    'TGG': 1.000,  # Trp\n}\nSCER_COPT_RATIO = {\n    'GCT': 3.919, 'GCC': 1.318, 'GCA': 0.150, 'GCG': 0.122,\n    'CGT': 1.554, 'CGC': 0.157, 'CGA': 0.042, 'CGG': 0.040, 'AGA': 4.273, 'AGG': 0.122,\n    'AAT': 0.193, 'AAC': 5.188,\n    'GAT': 0.485, 'GAC': 2.061,\n    'TGT': 3.671, 'TGC': 0.272,\n    'CAA': 6.547, 'CAG': 0.153,\n    'GAA': 4.168, 'GAG': 0.240,\n    'GGT': 10.496, 'GGC': 0.304, 'GGA': 0.120, 'GGG': 0.111,\n    'CAT': 0.281, 'CAC': 3.561,\n    'ATT': 1.261, 'ATC': 2.669, 'ATA': 0.108,\n    'CTT': 0.542, 'CTC': 0.744, 'CTA': 0.285, 'CTG': 3.759, 'TTA': 0.301, 'TTG': 0.527,\n    'AAA': 0.208, 'AAG': 4.811,\n    'TTT': 0.251, 'TTC': 3.985,\n    'CCT': 0.423, 'CCC': 0.144, 'CCA': 6.153, 'CCG': 0.126,\n    'TCT': 2.819, 'TCC': 2.565, 'TCA': 0.331, 'TCG': 0.191, 'AGT': 0.364, 'AGC': 0.413,\n    'ACT': 2.056, 'ACC': 2.640, 'ACA': 1.018, 'ACG': 0.126,\n    'TAT': 0.230, 'TAC': 4.340,\n    'GTT': 1.950, 'GTC': 2.696, 'GTA': 0.135, 'GTG': 0.221,\n    'ATG': 1.000,  # Met\n    'TGG': 1.000,  # Trp\n}\n\ndef copt_ratio_table_for_species(species_key: str) -> Dict[str, float]:\n    if species_key == \"scer\":\n        return {c: SCER_COPT_RATIO.get(c, 1.0) for c in SENSE_CODONS}\n    return {c: ECO_COPT_RATIO.get(c, 1.0) for c in SENSE_CODONS}\n\n# ---------------- CAI / tAI / ENC calculators ----------------\ndef calculate_index(seq: str, weights: Dict[str, float]) -> float:\n    seq = normalize_seq(seq)\n    log_sum, count = 0.0, 0\n    for i in range(0, len(seq) - 2, 3):\n        w = weights.get(seq[i:i+3], 0.0)\n        if w > 0.0:\n            log_sum += math.log(w); count += 1\n    return math.exp(log_sum / count) if count else 0.0\n\ndef calculate_cai(seq: str, cai_w: Dict[str, float]) -> float: return calculate_index(seq, cai_w)\ndef calculate_tai(seq: str, tai_w: Dict[str, float]) -> float: return calculate_index(seq, tai_w)\n\ndef calculate_enc(seq: str) -> float:\n    seq = normalize_seq(seq)\n    aa_codon_counts: Dict[str, Counter[str]] = defaultdict(Counter)\n    for i in range(0, len(seq) - 2, 3):\n        codon = seq[i:i+3]\n        aa = AA_FOR.get(codon)\n        if aa:\n            aa_codon_counts[aa][codon] += 1\n    Fk_list: List[Tuple[int, float]] = []\n    for codons in aa_codon_counts.values():\n        k = len(codons)\n        if k <= 1: continue\n        n = sum(codons.values())\n        fk = sum((c / n) ** 2 for c in codons.values())\n        if n > 1:\n            Fk = (n * fk - 1) / (n - 1)\n            if Fk > 0: Fk_list.append((k, Fk))\n    if not Fk_list: return 61.0\n    try: return float(2 + sum(k for k, _ in Fk_list) / sum(1 / Fk for _, Fk in Fk_list))\n    except ZeroDivisionError: return 61.0\n\n# ---------------- Copt (ratio/log2) + Binary % ----------------\ndef copt_ratio_for_gene(seq: str, codon_ratio: Dict[str, float]) -> Tuple[float, float]:\n    seq = normalize_seq(seq)\n    logs = []\n    for i in range(0, len(seq) - 2, 3):\n        c = seq[i:i+3]\n        if c in AA_FOR:\n            r = max(codon_ratio.get(c, 1.0), 1e-12)\n            logs.append(math.log(r, 2))\n    if not logs:\n        return 1.0, 0.0\n    mean_log2 = sum(logs) / len(logs)\n    gm_ratio = float(2 ** mean_log2)\n    return gm_ratio, float(mean_log2)\n\nBINARY_THRESHOLD = 1.0  # codon considered \"optimal\" if ratio >= 1\n\ndef copt_percent_for_gene(seq: str, codon_ratio: Dict[str, float], threshold: float = BINARY_THRESHOLD) -> float:\n    seq = normalize_seq(seq)\n    total, optimal = 0, 0\n    for i in range(0, len(seq) - 2, 3):\n        c = seq[i:i+3]\n        if c in AA_FOR:\n            total += 1\n            if codon_ratio.get(c, 1.0) >= threshold:\n                optimal += 1\n    return (optimal / total * 100.0) if total > 0 else 0.0\n\n# ---------------- Sequence helpers ----------------\ndef parse_sequences_from_text(text: str) -> List[Tuple[str, str]]:\n    text = (text or \"\").strip()\n    if not text: return []\n    if text.startswith(\">\"):\n        entries, sid, buf = [], None, []\n        for line in text.splitlines():\n            if line.startswith(\">\"):\n                if sid is not None and buf: entries.append((sid, \"\".join(buf)))\n                sid, buf = line[1:].strip() or f\"seq{len(entries)+1}\", []\n            else:\n                buf.append(line.strip())\n        if sid is not None: entries.append((sid, \"\".join(buf)))\n        return [(sid, normalize_seq(seq)) for sid, seq in entries if normalize_seq(seq)]\n    else:\n        seqs = [normalize_seq(l) for l in text.splitlines() if l.strip()]\n        return [(f\"seq{i+1}\", s) for i, s in enumerate(seqs) if s]\n\n# ---------------- UI ----------------\nhelp_modal = ui.modal(\n    ui.h3(\"Help & Notes\"),\n    ui.p(\"This app computes CAI, tAI, ENC, and Copt metrics for coding sequences.\"),\n    ui.h4(\"CAI\"),\n    ui.tags.ul(\n        ui.tags.li(\"Codon Adaptation Index from Sharp et al.\"),\n        ui.tags.li(\"Weights from public data\"),\n    ),\n    ui.h4(\"tAI\"),\n    ui.tags.ul(\n        ui.tags.li(\"tRNA Adaptation Index from dos Reis et al.\"),\n        ui.tags.li(\"Weights from public data\"),\n    ),\n    ui.h4(\"ENC\"),\n    ui.tags.ul(\n        ui.tags.li(\"Effective Number of Codons from Wright\"),\n    ),\n    ui.h4(\"Copt\"),\n    ui.tags.ul(\n        ui.tags.li(\"Per-codon values are High/Low usage ratios from Zhou et al.\"),\n        ui.tags.li(\"Copt_ratio = geometric mean of per-codon ratios; Copt_log2 = average log2 ratio.\"),\n        ui.tags.li(f\"Copt (%) = % of codons with ratio \u2265 {BINARY_THRESHOLD:.2f} (binary optimal/non-optimal).\"),\n        ui.tags.li(\"Single-codon AAs (ATG, TGG) are neutral (ratio = 1.0).\"),\n    ),\n    easy_close=True,\n    footer=ui.input_action_button(\"help_close\", \"Close\"),\n    size=\"l\",\n)\n\napp_ui = ui.page_fillable(\n    ui.navset_bar(\n        ui.nav_panel(\n            \"App\",\n            ui.layout_sidebar(\n                ui.sidebar(\n                    ui.input_action_button(\"help_open\", \"Help\"),\n                    ui.hr(),\n                    ui.h4(\"Input mode\"),\n                    ui.input_radio_buttons(\n                        \"input_mode\", None,\n                        choices={\"upload\": \"Upload FASTA\", \"paste\": \"Paste sequences\", \"table\": \"Upload table (CSV)\"},\n                        selected=\"upload\"\n                    ),\n                    ui.panel_conditional(\"input.input_mode == 'upload'\",\n                        ui.input_file(\"fasta\", \"Upload FASTA\", accept=[\".fa\",\".fasta\",\".fna\"])\n                    ),\n                    ui.panel_conditional(\"input.input_mode == 'paste'\",\n                        ui.input_text_area(\"seq_text\", \"Paste FASTA or one sequence per line\", rows=8)\n                    ),\n                    ui.panel_conditional(\"input.input_mode == 'table'\",\n                        ui.TagList(\n                            ui.input_file(\"table_file\", \"Upload CSV table\", accept=[\".csv\"]),\n                            ui.output_ui(\"table_col_picker\"),\n                            ui.input_select(\"fixed_species\", \"Set species for ALL rows (optional; overrides column)\",\n                                            choices={\"\": \"(none)\", \"ecoli\": \"E. coli\", \"scer\": \"S. cerevisiae\"},\n                                            selected=\"\")\n                        )\n                    ),\n                    ui.hr(),\n                    ui.h4(\"Species for CAI/tAI (FASTA/Paste modes)\"),\n                    ui.input_radio_buttons(\"species\", None,\n                        choices={\"ecoli\": \"E. coli (built-in)\", \"scer\": \"S. cerevisiae (built-in)\"},\n                        selected=\"ecoli\"),\n                    ui.input_switch(\"combined\", \"Combine plots\", value=False),\n                    ui.download_button(\"download_csv\", \"Download metrics (CSV)\"),\n                    ui.download_button(\"download_plot\", \"Download plot (PNG)\"),\n                    ui.panel_conditional(\"input.input_mode == 'table'\",\n                        ui.download_button(\"download_augmented\", \"Download augmented table (CSV)\")\n                    ),\n                    width=380\n                ),\n                ui.layout_columns(\n                    ui.card(ui.card_header(\"Codon Metrics Table\"), ui.output_data_frame(\"metrics_df\")),\n                    ui.card(ui.card_header(\"Copy-paste table (TSV)\"), ui.output_ui(\"metrics_tsv_ui\")),\n                ),\n                ui.card(ui.card_header(\"CAI / tAI / ENC / Copt\"),\n                        ui.output_plot(\"metrics_plot\", height=\"460px\"))\n            ),\n        ),\n        ui.nav_spacer(),\n        ui.nav_control(ui.a(\"\u2b50  CAI \u2022 tAI \u2022 ENC \u2022 Copt\", href=\"#\")),\n        title=\"Codon Metrics (CAI, tAI, ENC, Copt)\"\n    )\n)\n\n# ---------------- Common helpers for metrics rows ----------------\ndef active_sets_for_species(species_key: str) -> Tuple[Dict[str,float], Dict[str,float], Dict[str,float]]:\n    if species_key == \"scer\":\n        return SCER_CAI, SCER_TAI, copt_ratio_table_for_species(\"scer\")\n    return ECOLI_CAI, ECOLI_TAI, copt_ratio_table_for_species(\"ecoli\")\n\ndef compute_all_metrics(seq: str, species_key: str) -> Dict[str, float]:\n    cai_w, tai_w, copt_ratio = active_sets_for_species(species_key)\n    ratio_gm, log2_mean = copt_ratio_for_gene(seq, copt_ratio)\n    copt_percent = copt_percent_for_gene(seq, copt_ratio, BINARY_THRESHOLD)\n    return {\n        \"CAI\": round(calculate_cai(seq, cai_w), 4),\n        \"tAI\": round(calculate_tai(seq, tai_w), 4),\n        \"ENC\": round(calculate_enc(seq), 2),\n        \"Copt_ratio\": round(ratio_gm, 4),\n        \"Copt_log2\": round(log2_mean, 4),\n        \"Copt (%)\": round(copt_percent, 2),\n    }\n\n# ---------------- Server ----------------\ndef server(input: Inputs, output: Outputs, session: Session):\n    # Help modal controls\n    @reactive.effect\n    @reactive.event(input.help_open)\n    def _open_help(): ui.modal_show(help_modal)\n    @reactive.effect\n    @reactive.event(input.help_close)\n    def _close_help(): ui.modal_remove()\n\n    # ===== FASTA / Paste modes =====\n    @reactive.calc\n    def metrics_df_calc_fp() -> pd.DataFrame:\n        sp = input.species()\n        try:\n            seqs: List[Tuple[str, str]] = []\n            if input.input_mode() == \"upload\":\n                files = input.fasta()\n                if files:\n                    for rec in SeqIO.parse(files[0][\"datapath\"], \"fasta\"):\n                        seqs.append((rec.id, str(rec.seq)))\n            elif input.input_mode() == \"paste\":\n                seqs.extend(parse_sequences_from_text(input.seq_text() or \"\"))\n\n            if not seqs:\n                return pd.DataFrame(columns=[\n                    \"ID\",\"CAI\",\"tAI\",\"ENC\",\"Copt_ratio\",\"Copt_log2\",\"Copt (%)\"\n                ])\n\n            rows = []\n            for sid, s in seqs:\n                m = compute_all_metrics(s, sp)\n                rows.append({\"ID\": sid, **m})\n            return pd.DataFrame(rows)[\n                [\"ID\",\"CAI\",\"tAI\",\"ENC\",\"Copt_ratio\",\"Copt_log2\",\"Copt (%)\"]\n            ]\n        except Exception as e:\n            return pd.DataFrame({\"Error\":[str(e)]})\n\n    # ===== TABLE mode =====\n    @reactive.calc\n    def table_df_raw() -> Optional[pd.DataFrame]:\n        if input.input_mode() != \"table\":\n            return None\n        f = input.table_file()\n        if not f:\n            return None\n        try:\n            return pd.read_csv(f[0][\"datapath\"])\n        except Exception as e:\n            return pd.DataFrame({\"Error\":[f\"Failed to read CSV: {e}\"]})\n\n    @output\n    @render.ui\n    def table_col_picker():\n        df = table_df_raw()\n        if df is None or df.empty or \"Error\" in df.columns:\n            return ui.help_text(\"Upload a CSV to choose columns.\")\n        cols = list(df.columns)\n        # cheap guesses\n        seq_guess = next((c for c in cols if c.lower() in (\"cds\",\"sequence\",\"seq\",\"cds_seq\",\"CDS\")), cols[0])\n        id_guess  = next((c for c in cols if c.lower() in (\"id\",\"tx_id\",\"gene\",\"name\",\"locus\",\"accession\")), cols[0])\n        species_guess = next((c for c in cols if c.lower() in (\"species\",\"organism\",\"host\")), \"\")\n        return ui.TagList(\n            ui.input_select(\"id_col\", \"ID column\", choices=cols, selected=id_guess),\n            ui.input_select(\"seq_col\", \"Sequence column\", choices=cols, selected=seq_guess),\n            ui.input_select(\"species_col\", \"Species column (optional: 'ecoli' or 'scer')\",\n                            choices=[\"(none)\"] + cols, selected=species_guess or \"(none)\")\n        )\n\n    @reactive.calc\n    def metrics_df_calc_table() -> pd.DataFrame:\n        df = table_df_raw()\n        if df is None or df.empty:\n            return pd.DataFrame(columns=[\n                \"ID\",\"CAI\",\"tAI\",\"ENC\",\"Copt_ratio\",\"Copt_log2\",\"Copt (%)\"\n            ])\n        if \"Error\" in df.columns:\n            return df\n\n        id_col = input.id_col() if \"id_col\" in input else None\n        seq_col = input.seq_col() if \"seq_col\" in input else None\n        species_col_sel = input.species_col() if \"species_col\" in input else \"(none)\"\n        fixed_species = input.fixed_species() if \"fixed_species\" in input else \"\"\n\n        if not id_col or id_col not in df.columns:\n            id_col = df.columns[0]\n        if not seq_col or seq_col not in df.columns:\n            # No usable sequence column\n            return pd.DataFrame({\"Error\":[\n                \"Select a valid sequence column in the sidebar (Table mode).\"\n            ]})\n\n        rows = []\n        for _, r in df.iterrows():\n            sid = str(r[id_col])\n            seq = normalize_seq(str(r[seq_col]))\n            if not seq:\n                rows.append({\"ID\": sid, \"CAI\": float(\"nan\"), \"tAI\": float(\"nan\"),\n                             \"ENC\": float(\"nan\"), \"Copt_ratio\": float(\"nan\"),\n                             \"Copt_log2\": float(\"nan\"), \"Copt (%)\": float(\"nan\")})\n                continue\n\n            # Determine species for this row\n            if fixed_species:\n                sp = fixed_species\n            else:\n                if species_col_sel and species_col_sel != \"(none)\" and species_col_sel in df.columns:\n                    val = str(r[species_col_sel]).strip().lower()\n                    sp = \"scer\" if val.startswith(\"scer\") or val in {\"s.cer\",\"s cerevisiae\",\"s. cerevisiae\",\"yeast\"} else \\\n                         \"ecoli\" if val.startswith(\"e\") or \"coli\" in val else \"ecoli\"\n                else:\n                    sp = \"ecoli\"\n\n            m = compute_all_metrics(seq, sp)\n            rows.append({\"ID\": sid, **m})\n        return pd.DataFrame(rows)[\n            [\"ID\",\"CAI\",\"tAI\",\"ENC\",\"Copt_ratio\",\"Copt_log2\",\"Copt (%)\"]\n        ]\n\n    # ===== Unified outputs (show metrics table depending on mode) =====\n    def metrics_df_current() -> pd.DataFrame:\n        mode = input.input_mode()\n        if mode == \"table\":\n            return metrics_df_calc_table()\n        return metrics_df_calc_fp()\n\n    # Interactive table\n    @render.data_frame\n    def metrics_df():\n        return render.DataTable(metrics_df_current())\n\n    # Copy-paste TSV\n    @render.ui\n    def metrics_tsv_ui():\n        df = metrics_df_current()\n        cols = [\"ID\",\"CAI\",\"tAI\",\"ENC\",\"Copt_ratio\",\"Copt_log2\",\"Copt (%)\"]\n        if df.empty:\n            tsv = \"\\t\".join(cols)\n        else:\n            # if an Error column is present, show it plainly\n            if \"Error\" in df.columns:\n                tsv = df.to_csv(sep=\"\\t\", index=False, lineterminator=\"\\n\")\n            else:\n                tsv = df[cols].to_csv(sep=\"\\t\", index=False, lineterminator=\"\\n\")\n        return ui.TagList(\n            ui.input_action_button(\"copy_btn\", \"Copy to clipboard\"),\n            ui.tags.textarea(\n                tsv, id=\"tsv_area\", readonly=True,\n                style=(\"width:100%; height:260px; font-family: ui-monospace, SFMono-Regular, \"\n                       \"Menlo, Monaco, Consolas, 'Liberation Mono', 'Courier New', monospace;\")\n            ),\n            ui.tags.script(\n                \"\"\"\n                (function(){\n                  const btn = document.getElementById(\"copy_btn\");\n                  const ta  = document.getElementById(\"tsv_area\");\n                  if (!btn || !ta) return;\n                  btn.onclick = async function(){\n                    ta.focus(); ta.select(); ta.setSelectionRange(0, ta.value.length);\n                    try { await navigator.clipboard.writeText(ta.value); }\n                    catch (e) { document.execCommand(\"copy\"); }\n                  };\n                })();\n                \"\"\"\n            )\n        )\n\n    # Plot\n    def make_boxplot_figure(df: pd.DataFrame, combined: bool):\n        if df.empty or (\"Error\" in df.columns):\n            fig = plt.figure(figsize=(4, 2))\n            plt.text(0.5, 0.5, \"Provide sequences\", ha=\"center\", va=\"center\")\n            plt.axis(\"off\"); return fig\n        metrics = [\"CAI\",\"tAI\",\"ENC\",\"Copt_ratio\",\"Copt_log2\",\"Copt (%)\"]\n        if combined:\n            dfm = df.melt(id_vars=[\"ID\"], value_vars=metrics, var_name=\"Metric\", value_name=\"Value\")\n            plt.figure(figsize=(10, 4)); sns.boxplot(x=\"Metric\", y=\"Value\", data=dfm)\n            plt.ylabel(\"Value\"); plt.title(\"Codon Usage Metrics\"); plt.tight_layout()\n            return plt.gcf()\n        fig, axes = plt.subplots(1, len(metrics), figsize=(4*len(metrics), 4))\n        for ax, col in zip(axes, metrics):\n            sns.boxplot(y=df[col], ax=ax, width=0.3)\n            ax.set_title(col); ax.set_ylabel(col); ax.set_xticks([])\n        plt.tight_layout(); return fig\n\n    @render.plot(alt=\"Boxplots of CAI, tAI, ENC, and Copt\")\n    def metrics_plot():\n        return make_boxplot_figure(metrics_df_current(), combined=bool(input.combined()))\n\n    # Downloads (metrics only)\n    @render.download(filename=\"codon_metrics.csv\")\n    def download_csv():\n        df = metrics_df_current()\n        with io.StringIO() as s:\n            df.to_csv(s, index=False); yield s.getvalue()\n\n    @render.download(filename=\"codon_metrics_boxplot.png\")\n    def download_plot():\n        fig = make_boxplot_figure(metrics_df_current(), combined=bool(input.combined()))\n        with io.BytesIO() as buf:\n            fig.savefig(buf, format=\"png\", dpi=300, bbox_inches=\"tight\")\n            plt.close(fig); yield buf.getvalue()\n\n    # Download augmented (TABLE mode only): merges original CSV + computed columns by ID\n    @render.download(filename=lambda: augmented_name())\n    def download_augmented():\n        # guard: only in table mode\n        if input.input_mode() != \"table\":\n            yield b\"\"; return\n        raw = table_df_raw()\n        metrics = metrics_df_calc_table()\n        if raw is None or raw.empty or metrics.empty or \"Error\" in metrics.columns:\n            with io.StringIO() as s:\n                s.write(\"Error: no augmented output available.\\n\")\n                yield s.getvalue().encode(\"utf-8\")\n            return\n        # Merge on ID\n        # If ID column name != 'ID', we still export both (original ID col + computed 'ID').\n        # Prefer left-merge to preserve row order and all original columns.\n        id_col = input.id_col() if \"id_col\" in input else None\n        if id_col and id_col in raw.columns:\n            merged = raw.merge(metrics, left_on=id_col, right_on=\"ID\", how=\"left\")\n        else:\n            # no id column selected; append metrics in order (best effort)\n            merged = pd.concat([raw.reset_index(drop=True), metrics.reset_index(drop=True)], axis=1)\n        with io.StringIO() as s:\n            merged.to_csv(s, index=False)\n            yield s.getvalue().encode(\"utf-8\")\n\n    def augmented_name() -> str:\n        f = input.table_file()\n        if f:\n            name = f[0][\"name\"]\n            base = name.rsplit(\".\", 1)[0]\n            return f\"{base}_with_metrics.csv\"\n        return \"table_with_metrics.csv\"\n\napp = App(app_ui, server)", "type": "text"}, {"name": "Cut45.py", "content": "s = \"ATGAGCAAAGGTGAAGAACTGTTTACCGGCGTTGTGCCGATTCTGGTGGAACTGGACGGTGATGTTAACGGCCACAAATTCAGCGTTCGTGGCGAAGGCGAAGGTGACGCTACCAACGGTAAACTGACCCTGAAATTCATCTGCACCACCGGTAAACTGCCGGTTCCGTGGCCGACCCTGGTAACCACCCTGACCTATGGCGTTCAGTGCTTCAGCCGCTACCCGGACCACATGAAACGCCACGACTTCTTCAAATCTGCTATGCCGGAAGGCTATGTACAGGAACGTACCATCAGCTTCAAAGACGACGGCACCTACAAAACCCGTGCGGAAGTTAAATTCGAAGGCGACACCCTGGTTAACCGCATCGAACTGAAAGGTATCGATTTCAAAGAAGACGGCAACATCCTGGGTCACAAACTGGAATACAACTTCAACTCTCACAACGTTTACATTACCGCCGACAAACAGAAAAACGGCATCAAAGCTAACTTCAAAATCCGTCACAACGTAGAAGACGGTTCTGTACAGCTGGCGGACCATTACCAGCAGAACACCCCGATCGGTGATGGCCCGGTACTGCTGCCGGACAACCACTACCTGAGCACCCAGTCCGTTCTGTCTAAAGATCCGAACGAAAAACGTGACCACATGGTTCTGCTGGAATTTGTTACCGCTGCTGGCATCACCCACGGTATGGACGAACTGTACAAA\"\nresult = s[45:]\nprint(result)", "type": "text"}, {"name": "backfill.py", "content": "import pandas as pd\nimport numpy as np\nfrom Bio import SeqIO\n\n# -----------------------------\n# Hardcoded paths and settings\n# -----------------------------\nINPUT_CSV    = \"TE_with_cds_clean.csv\"\nGENBANK_GB   = \"GCF_000005845.2_ASM584v2_genomic.gbff\"\nOUTPUT_CSV   = \"TE_with_cds_backfill.csv\"\nSEQ_COL      = \"cds_seq\"   # column to fill\nINCLUDE_STOP = True        # keep terminal stop codon if present\n\nUNRESOLVED_LIST = \"unresolved_btags.txt\"\nSTILL_MISSING_CSV = \"still_missing_rows.csv\"\n# -----------------------------\n\ndef maybe_drop_stop(seq: str, include_stop: bool) -> str:\n    seq = (seq or \"\").upper()\n    if not include_stop and len(seq) >= 3 and len(seq) % 3 == 0:\n        if seq[-3:] in (\"TAA\", \"TAG\", \"TGA\"):\n            return seq[:-3]\n    return seq\n\ndef build_locus_to_cds(gb_path: str, include_stop: bool = True):\n    \"\"\"Return dict: locus_tag -> {cds_seq, cds_len_nt, protein_id, gene} (skip pseudogenes).\n       If duplicates exist, keep the longest CDS.\n    \"\"\"\n    locus_map = {}\n    for rec in SeqIO.parse(gb_path, \"genbank\"):\n        for f in rec.features:\n            if f.type != \"CDS\":\n                continue\n            if \"pseudo\" in f.qualifiers:\n                continue\n            locus_tag = (f.qualifiers.get(\"locus_tag\", [None])[0] or \"\").strip()\n            if not locus_tag:\n                continue\n            try:\n                seq_str = str(f.extract(rec.seq)).upper()\n            except Exception:\n                continue\n            seq_str = maybe_drop_stop(seq_str, include_stop)\n            entry = {\n                \"cds_seq\": seq_str,\n                \"cds_len_nt\": len(seq_str),\n                \"protein_id\": f.qualifiers.get(\"protein_id\", [None])[0],\n                \"gene\": f.qualifiers.get(\"gene\", [None])[0],\n            }\n            if (locus_tag not in locus_map) or (entry[\"cds_len_nt\"] > locus_map[locus_tag][\"cds_len_nt\"]):\n                locus_map[locus_tag] = entry\n    return locus_map\n\ndef main():\n    df = pd.read_csv(INPUT_CSV)\n\n    # Ensure required columns exist\n    if \"locus_tag\" not in df.columns:\n        raise ValueError(\"Input CSV must contain a 'locus_tag' column.\")\n    if SEQ_COL not in df.columns:\n        df[SEQ_COL] = np.nan\n\n    # Identify rows missing sequence\n    missing_mask = df[SEQ_COL].isna() | (df[SEQ_COL].astype(str).str.len() == 0)\n    n_missing_init = int(missing_mask.sum())\n    print(f\"[INFO] Rows missing {SEQ_COL} before backfill: {n_missing_init}\")\n\n    if n_missing_init == 0:\n        df.to_csv(OUTPUT_CSV, index=False)\n        # Empty reports\n        open(UNRESOLVED_LIST, \"w\").close()\n        pd.DataFrame(columns=[\"gene\",\"locus_tag\"]).to_csv(STILL_MISSING_CSV, index=False)\n        print(f\"[OK] Nothing to fill. Wrote {OUTPUT_CSV}\")\n        return\n\n    # Build map from GenBank\n    locus_map = build_locus_to_cds(GENBANK_GB, include_stop=INCLUDE_STOP)\n\n    # Ensure metadata cols exist\n    for col in [\"cds_len_nt\", \"protein_id\", \"gene_from_gb\"]:\n        if col not in df.columns:\n            df[col] = np.nan\n\n    # Backfill by locus_tag\n    filled = 0\n    unresolved_btags = set()\n\n    for idx in df.index[missing_mask]:\n        btag = df.at[idx, \"locus_tag\"]\n        if pd.isna(btag):\n            unresolved_btags.add(\"\")  # blank/missing btag\n            continue\n        btag = str(btag).strip()\n        if not btag or btag not in locus_map:\n            unresolved_btags.add(btag)\n            continue\n\n        entry = locus_map[btag]\n        df.at[idx, SEQ_COL]       = entry[\"cds_seq\"]\n        df.at[idx, \"cds_len_nt\"]  = entry[\"cds_len_nt\"]\n        df.at[idx, \"protein_id\"]  = entry[\"protein_id\"]\n        df.at[idx, \"gene_from_gb\"]= entry[\"gene\"]\n        filled += 1\n\n    # Recompute missing after fill (don\u2019t double-count)\n    missing_mask_after = df[SEQ_COL].isna() | (df[SEQ_COL].astype(str).str.len() == 0)\n    n_missing_final = int(missing_mask_after.sum())\n    print(f\"[INFO] Filled {filled} row(s). Still missing: {n_missing_final}\")\n\n    # Write outputs\n    df.to_csv(OUTPUT_CSV, index=False)\n    print(f\"[OK] Wrote {OUTPUT_CSV}\")\n\n    # Unresolved list (only the ones that were actually missing at start)\n    # Filter unresolved_btags to those that correspond to rows still missing\n    still_missing_tags = (\n        df.loc[missing_mask_after, \"locus_tag\"]\n          .astype(str)\n          .str.strip()\n          .tolist()\n    )\n    unresolved_filtered = sorted(set([t for t in unresolved_btags if t in still_missing_tags]))\n    with open(UNRESOLVED_LIST, \"w\") as fh:\n        for t in unresolved_filtered:\n            if t:  # skip empty\n                fh.write(f\"{t}\\n\")\n    print(f\"[OK] Wrote unresolved b-tags to {UNRESOLVED_LIST} ({len(unresolved_filtered)} item(s)).\")\n\n    # Also dump a small CSV with the still-missing rows (handy for inspection)\n    cols_to_show = [c for c in [\"gene\",\"locus_tag\", SEQ_COL, \"cds_len_nt\", \"protein_id\"] if c in df.columns]\n    df.loc[missing_mask_after, cols_to_show].to_csv(STILL_MISSING_CSV, index=False)\n    print(f\"[OK] Wrote still-missing rows to {STILL_MISSING_CSV}\")\n\nif __name__ == \"__main__\":\n    main()", "type": "text"}, {"name": "clean.py", "content": "import pandas as pd\n\nte = pd.read_csv(\"TE_with_cds_backfill.csv\")\n\nte = te.drop(columns=['gene_from_gb'])   # assign back\n\nte.to_csv(\"TE_with_cds_backfill_clean.csv\", index=False)", "type": "text"}, {"name": "dataclean.py", "content": "import pandas as pd\nimport numpy as np\n\n# Load\ndf = pd.read_csv(\"te_table.csv\")\n\n# 1) Identify TE columns\nte_cols = [c for c in df.columns if c.startswith(\"te\")]\n\n# 2) Replace bad values with NaN\ndf[te_cols] = df[te_cols].replace([\"#DIV/0!\", 0, 0.0], np.nan).astype(float)\n\n# 3) Count non-missing TE values\ndf[\"TE_n_nonmissing\"] = df[te_cols].notna().sum(axis=1)\n\n# 4) Row-wise mean excluding NaN (will be NaN if all are NaN)\ndf[\"TE_mean\"] = df[te_cols].mean(axis=1, skipna=True)\n\n# 5) Explicit flag when all three are NaN\ndf[\"TE_all_missing\"] = df[\"TE_n_nonmissing\"] == 0\n\n# (optional) if you want TE_mean explicitly set to NaN when all missing (it already will be)\ndf.loc[df[\"TE_all_missing\"], \"TE_mean\"] = np.nan\n\n# Save\ndf.to_csv(\"te_table_with_mean.csv\", index=False)\nprint(\"Wrote te_table_with_mean.csv\")", "type": "text"}, {"name": "merge.py", "content": "#!/usr/bin/env python3\nimport pandas as pd\n\nTE_PATH = \"te_table_with_mean.csv\"   # must contain 'gene' and 'locus_tag'\nCDS_PATH = \"te_with_codons - Li.csv\"           # produced from your GenBank parsing\nOUT_PATH = \"te_with_cds.csv\"\n\n# 1) Load\nte = pd.read_csv(TE_PATH)\ncds = pd.read_csv(CDS_PATH)\n\n# 2) Decide which sequence column exists in CDS: prefer 'cds_seq', fallback to 'codon_seq'\nseq_col = None\nfor candidate in [\"cds_seq\", \"codon_seq\"]:\n    if candidate in cds.columns:\n        seq_col = candidate\n        break\nif seq_col is None:\n    raise ValueError(\n        f\"No sequence column found in {CDS_PATH}. \"\n        \"Expected one of: 'cds_seq' or 'codon_seq'. \"\n        f\"Found columns: {list(cds.columns)}\"\n    )\n\n# 3) Build a slim CDS table with only needed columns (and only those that actually exist)\nkeep_cols = [\"gene\", \"locus_tag\", seq_col, \"cds_len_nt\", \"protein_id\", 'TE']\nkeep_cols = [c for c in keep_cols if c in cds.columns]\ncds_slim = cds[keep_cols].copy()\n\n# 4) Primary merge on locus_tag (dedupe on that key first)\nif \"locus_tag\" in cds_slim.columns:\n    cds_by_locus = cds_slim.dropna(subset=[\"locus_tag\"]).drop_duplicates(subset=[\"locus_tag\"])\n    merged = te.merge(cds_by_locus, on=\"locus_tag\", how=\"left\", validate=\"m:1\")\nelse:\n    # If locus_tag isn't present in CDS, start with a gene merge directly\n    merged = te.copy()\n\n# 5) Fallback merge on gene and coalesce any missing values\nif \"gene\" in te.columns and \"gene\" in cds_slim.columns:\n    cds_by_gene = cds_slim.dropna(subset=[\"gene\"]).drop_duplicates(subset=[\"gene\"]).copy()\n\n    # rename value columns so we can combine_first() cleanly\n    value_cols = [c for c in [seq_col, \"cds_len_nt\", \"protein_id\"] if c in cds_by_gene.columns]\n    rename_map = {c: f\"{c}_gene\" for c in value_cols}\n    cds_by_gene = cds_by_gene.rename(columns=rename_map)\n\n    # merge on gene\n    merged_gene = te.merge(cds_by_gene, on=\"gene\", how=\"left\", validate=\"m:1\")\n\n    # coalesce: fill missing from gene-based merge\n    for c in value_cols:\n        gene_c = f\"{c}_gene\"\n        if c in merged.columns and gene_c in merged_gene.columns:\n            merged[c] = merged[c].combine_first(merged_gene[gene_c])\n        elif c not in merged.columns and gene_c in merged_gene.columns:\n            merged[c] = merged_gene[gene_c]  # if primary merge never created the column\nelse:\n    print(\"Warning: could not run gene-based fallback; 'gene' not present in both tables.\")\n\n# 6) Report unmatched after both passes\nn_unmatched = merged[seq_col].isna().sum()\nprint(f\"Final unmatched rows (no sequence): {n_unmatched}\")\n\n# 7) Save\nmerged.to_csv(OUT_PATH, index=False)\nprint(f\"Wrote {OUT_PATH} with sequence column '{seq_col}'\")", "type": "text"}, {"name": "requirements.txt", "content": "pandas\nmatplotlib\nseaborn\nbiopython", "type": "text"}]